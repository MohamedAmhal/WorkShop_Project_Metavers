{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11265621,"sourceType":"datasetVersion","datasetId":7041779},{"sourceId":232449949,"sourceType":"kernelVersion"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NoteBook 1 : Fine-tune GPT 2 LMM:","metadata":{}},{"cell_type":"markdown","source":"**Fine-tune LLM GPT2**\n\nThis notebook is divided into two main parts, each focused on enhancing the capabilities of the GPT-2 language model through fine-tuning and data augmentation.\n\n**Part 1: Fine-tuning GPT-2 with Deepseek Conversations**\n\nIn the first section, we fine-tune the GPT-2 model using a dataset composed of conversational exchanges with **Deepseek**. This allows the model to understand and replicate the style and structure of human-like dialogue, improving its performance in generating coherent and contextually relevant responses.\n\n**Part 2: Exploring the GooAQ Dataset and Using ChromaDB**\n\nIn the second part, we explore a dataset called **GooAQ**, which is built from real user queries on the Google search platform. These questions reflect a wide range of natural language expressions and real-world information needs.\n\nTo further enhance the model's ability to provide accurate and relevant answers, we store the answers in **ChromaDB**, a vector database. This step allows for efficient retrieval of relevant responses and improves the overall performance of the system by combining fine-tuned generation with memory-based retrieval.\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Importing libraries","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling, MistralForCausalLM, TFAutoModelForCausalLM, TrainerCallback\nfrom datasets import load_dataset, Dataset\nimport json\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:48:25.425311Z","iopub.execute_input":"2025-04-07T13:48:25.425609Z","iopub.status.idle":"2025-04-07T13:49:01.812925Z","shell.execute_reply.started":"2025-04-07T13:48:25.425585Z","shell.execute_reply":"2025-04-07T13:49:01.812199Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## 2. logging into huggingface_hub","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:49:01.813924Z","iopub.execute_input":"2025-04-07T13:49:01.814497Z","iopub.status.idle":"2025-04-07T13:49:01.984727Z","shell.execute_reply.started":"2025-04-07T13:49:01.814470Z","shell.execute_reply":"2025-04-07T13:49:01.983274Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## 3. FINE TUNE USING JSON DATASET (Part 1) (deepseek convs):","metadata":{}},{"cell_type":"markdown","source":"##### 1. Load and prepare the data set:","metadata":{}},{"cell_type":"markdown","source":"In this part, we will load a dataset from a JSON file that stores simple conversational exchanges.","metadata":{}},{"cell_type":"code","source":"# load the data from json file\nwith open(\"/kaggle/input/jsondata/chatgpt_logs.json\", \"r\") as file:\n    chat_data = json.load(file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:15:02.531350Z","iopub.execute_input":"2025-04-06T18:15:02.531716Z","iopub.status.idle":"2025-04-06T18:15:02.536987Z","shell.execute_reply.started":"2025-04-06T18:15:02.531687Z","shell.execute_reply":"2025-04-06T18:15:02.536187Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# prepare the data (clean and transform into the json format)\ntexts = [f\"User: {conv['user']}\\nChatbot: {conv['chatbot']}\" for conv in chat_data]\ndataset = Dataset.from_dict({\"text\": texts})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:15:04.497452Z","iopub.execute_input":"2025-04-06T18:15:04.497810Z","iopub.status.idle":"2025-04-06T18:15:04.507355Z","shell.execute_reply.started":"2025-04-06T18:15:04.497780Z","shell.execute_reply":"2025-04-06T18:15:04.506655Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"##### 2. Import tokenizer and model (GPT2):","metadata":{}},{"cell_type":"code","source":"model_name = \"gpt2\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:15:06.374919Z","iopub.execute_input":"2025-04-06T18:15:06.375222Z","iopub.status.idle":"2025-04-06T18:15:06.978230Z","shell.execute_reply.started":"2025-04-06T18:15:06.375198Z","shell.execute_reply":"2025-04-06T18:15:06.977480Z"}},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"##### 3. Add the tokenizer:","metadata":{}},{"cell_type":"code","source":"# Add padding token :\nif tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    model.resize_token_embeddings(len(tokenizer), mean_resizing=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:15:10.271236Z","iopub.execute_input":"2025-04-06T18:15:10.271672Z","iopub.status.idle":"2025-04-06T18:15:10.936327Z","shell.execute_reply.started":"2025-04-06T18:15:10.271636Z","shell.execute_reply":"2025-04-06T18:15:10.935391Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Tokenizer the data :\ndef tokenize_function(examples):\n    tokens = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n    return tokens\n\n\n# map the fucntionnn\ntokenized_datasets = dataset.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:15:43.094000Z","iopub.execute_input":"2025-04-06T18:15:43.094323Z","iopub.status.idle":"2025-04-06T18:15:43.187539Z","shell.execute_reply.started":"2025-04-06T18:15:43.094297Z","shell.execute_reply":"2025-04-06T18:15:43.186698Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/30 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f66df146bb1402197aa5eb733543336"}},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"# testinngg :\nprint(tokenized_datasets[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:15:45.094628Z","iopub.execute_input":"2025-04-06T18:15:45.094922Z","iopub.status.idle":"2025-04-06T18:15:45.100867Z","shell.execute_reply.started":"2025-04-06T18:15:45.094899Z","shell.execute_reply":"2025-04-06T18:15:45.099750Z"}},"outputs":[{"name":"stdout","text":"{'text': \"User: hey how are you doing ?\\nChatbot: Hi! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help! How are *you* doing? ðŸ˜Š\", 'input_ids': [12982, 25, 17207, 703, 389, 345, 1804, 5633, 198, 30820, 13645, 25, 15902, 0, 314, 1101, 655, 257, 7166, 8796, 11, 523, 314, 836, 470, 423, 7666, 11, 475, 314, 1101, 994, 290, 3492, 284, 1037, 0, 1374, 389, 1635, 5832, 9, 1804, 30, 30325, 232, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [12982, 25, 17207, 703, 389, 345, 1804, 5633, 198, 30820, 13645, 25, 15902, 0, 314, 1101, 655, 257, 7166, 8796, 11, 523, 314, 836, 470, 423, 7666, 11, 475, 314, 1101, 994, 290, 3492, 284, 1037, 0, 1374, 389, 1635, 5832, 9, 1804, 30, 30325, 232, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257]}\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# testig ...\nprint(tokenized_datasets[10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:15:51.262948Z","iopub.execute_input":"2025-04-06T18:15:51.263218Z","iopub.status.idle":"2025-04-06T18:15:51.268919Z","shell.execute_reply.started":"2025-04-06T18:15:51.263198Z","shell.execute_reply":"2025-04-06T18:15:51.267841Z"}},"outputs":[{"name":"stdout","text":"{'text': 'User: What are the key differences between traditional machine learning and deep learning?\\nChatbot: Traditional machine learning and deep learning are both subsets of artificial intelligence, but they differ significantly in their approaches, architectures, and applications. Here are the key differences:\\n\\n### 1. **Feature Engineering**\\n   - **Traditional Machine Learning**: Requires manual feature extraction and engineering. Domain experts often need to identify and create relevant features from the raw data to improve model performance.\\n   - **Deep Learning**: Automatically learns features from raw data through multiple layers of neural networks. This eliminates the need for manual feature engineering, especially in complex tasks like image or speech recognition.\\n\\n### 2. **Model Architecture**\\n   - **Traditional Machine Learning**: Uses simpler algorithms such as linear regression, decision trees, support vector machines (SVM), and k-nearest neighbors (KNN). These models are typically shallow and have fewer parameters.\\n   - **Deep Learning**: Employs deep neural networks (DNNs) with multiple layers (e.g., convolutional neural networks (CNNs) for images, recurrent neural networks (RNNs) for sequences). These models are hierarchical and can capture intricate patterns in data.\\n\\n### 3. **Data Requirements**\\n   - **Traditional Machine Learning**: Works well with smaller datasets and structured data. It can achieve good performance with limited data, especially when features are well-defined.\\n   - **Deep Learning**: Requires large amounts of data to train effectively. It excels with unstructured data (e.g., images, text, audio) but may underperform with small datasets due to overfitting.\\n\\n### 4. **Computational Resources**\\n   - **Traditional Machine Learning**: Less computationally intensive and can often run on standard CPUs. Training and inference are faster and require less hardware.\\n   - **Deep Learning**: Highly computationally intensive, often requiring GPUs or TPUs for training. Deep models can take significant time and resources to train, especially for large datasets.\\n\\n### 5. **Interpretability**\\n   - **Traditional Machine Learning**: Models are generally more interpretable. For example, decision trees or linear models provide clear insights into how predictions are made.\\n   - **Deep Learning**: Models are often considered \"black boxes\" due to their complexity. Understanding why a deep learning model makes a specific prediction can be challenging.\\n\\n### 6. **Performance on Complex Tasks**\\n   - **Traditional Machine Learning**: Performs well on structured data and tasks with clear, well-defined features (e.g., classification, regression).\\n   - **Deep Learning**: Excels at complex tasks involving unstructured data, such as image recognition, natural language processing (NLP), and speech recognition, where patterns are hierarchical and abstract.\\n\\n### 7. **Training Time**\\n   - **Traditional Machine Learning**: Faster to train due to simpler models and smaller datasets.\\n   - **Deep Learning**: Training can be time-consuming, especially for large models and datasets, but often results in higher accuracy for complex tasks.\\n\\n### 8. **Scalability**\\n   - **Traditional Machine Learning**: Scales well with structured data but may struggle with high-dimensional or unstructured data.\\n   - **Deep Learning**: Highly scalable for large, high-dimensional datasets, making it suitable for big data applications.\\n\\n### 9. **Use Cases**\\n   - **Traditional Machine Learning**: Commonly used in applications like fraud detection, customer segmentation, and predictive maintenance.\\n   - **Deep Learning**: Applied in advanced tasks like autonomous driving, medical image analysis, language translation, and generative AI (e.g., GPT models).\\n\\n### Summary\\nTraditional machine learning is more interpretable, requires less data, and is computationally efficient, making it suitable for structured data and simpler tasks. Deep learning, on the other hand, excels at handling unstructured data, automatically learning features, and achieving state-of-the-art performance in complex tasks, but it demands large datasets and significant computational resources. The choice between the two depends on the specific problem, data availability, and resource constraints.', 'input_ids': [12982, 25, 1867, 389, 262, 1994, 5400, 1022, 4569, 4572, 4673, 290, 2769, 4673, 30, 198, 30820, 13645, 25, 29065, 4572, 4673, 290, 2769, 4673, 389, 1111, 6352, 1039, 286, 11666, 4430, 11, 475, 484, 13238, 5566, 287, 511, 10581, 11, 45619, 11, 290, 5479, 13, 3423, 389, 262, 1994, 5400, 25, 198, 198, 21017, 352, 13, 12429, 38816, 14044, 1174, 198, 220, 220, 532, 12429, 48485, 10850, 18252, 1174, 25, 26848, 10107, 3895, 22236, 290, 8705, 13, 20021, 6154, 1690, 761, 284, 5911, 290, 2251, 5981, 3033, 422, 262, 8246, 1366, 284, 2987, 2746, 2854, 13, 198, 220, 220, 532, 12429, 29744, 18252, 1174, 25, 17406, 4142, 22974, 3033, 422, 8246, 1366, 832, 3294, 11685, 286, 17019, 7686, 13, 770, 32311, 262, 761, 329, 10107, 3895, 8705, 11, 2592, 287, 3716, 8861, 588, 2939, 393, 4046, 9465, 13, 198, 198, 21017, 362, 13, 12429, 17633, 29778, 1174, 198, 220, 220, 532, 12429, 48485, 10850, 18252, 1174, 25, 36965, 18599, 16113, 884, 355, 14174, 20683, 11, 2551, 7150, 11, 1104, 15879, 8217, 357, 50, 15996, 828, 290, 479, 12, 710, 12423, 12020, 357, 42, 6144, 737, 2312, 4981, 389, 6032, 19337, 290, 423, 7380, 10007, 13, 198, 220, 220, 532, 12429, 29744, 18252, 1174, 25, 12645, 82, 2769, 17019, 7686, 357, 35, 6144, 82, 8, 351, 3294, 11685, 357, 68, 13, 70, 1539, 3063, 2122, 282, 17019, 7686, 357, 18474, 82, 8, 329, 4263, 11, 42465, 17019, 7686, 357, 49, 6144, 82, 8, 329, 16311, 737, 2312, 4981, 389, 38958, 290, 460, 8006, 28746, 7572, 287, 1366, 13, 198, 198, 21017, 513, 13, 12429, 6601, 24422, 1174, 198, 220, 220, 532, 12429, 48485, 10850, 18252, 1174, 25, 10933, 880, 351, 4833, 40522, 290, 20793, 1366, 13, 632, 460, 4620, 922, 2854, 351, 3614, 1366, 11, 2592, 618, 3033, 389, 880, 12, 23211, 13, 198, 220, 220, 532, 12429, 29744, 18252, 1174, 25, 26848, 1588, 6867, 286, 1366, 284, 4512, 6840, 13, 632, 27336, 82, 351, 555, 7249, 1522, 1366, 357, 68, 13, 70, 1539, 4263, 11, 2420, 11, 6597, 8, 475, 743, 739, 525, 687, 351, 1402, 40522, 2233, 284, 625, 32232, 13, 198, 198, 21017, 604, 13, 12429, 5377, 1996, 864, 13864, 1174, 198, 220, 220, 532, 12429, 48485, 10850, 18252, 1174, 25, 12892, 2653, 15208, 18590, 290, 460, 1690, 1057, 319, 3210, 32340, 13, 13614, 290, 32278, 389, 5443, 290, 2421, 1342, 6890, 13, 198, 220, 220, 532, 12429, 29744, 18252, 1174, 25, 38254, 2653, 15208, 18590, 11, 1690, 10616, 32516, 393, 309, 5105, 82, 329, 3047, 13, 10766, 4981, 460, 1011, 2383, 640, 290, 4133, 284, 4512, 11, 2592, 329, 1588, 40522, 13, 198, 198, 21017, 642, 13, 12429, 9492, 5310, 1799, 1174, 198, 220, 220, 532, 12429, 48485, 10850, 18252, 1174, 25, 32329, 389, 4143, 517, 6179, 540, 13, 1114, 1672, 11, 2551, 7150, 393, 14174, 4981, 2148, 1598, 17218, 656, 703, 16277, 389, 925, 13, 198, 220, 220, 532, 12429, 29744, 18252, 1174, 25, 32329, 389, 1690, 3177, 366, 13424, 10559, 1, 2233, 284, 511, 13357, 13, 28491, 1521, 257, 2769, 4673, 2746, 1838, 257, 2176, 17724], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [12982, 25, 1867, 389, 262, 1994, 5400, 1022, 4569, 4572, 4673, 290, 2769, 4673, 30, 198, 30820, 13645, 25, 29065, 4572, 4673, 290, 2769, 4673, 389, 1111, 6352, 1039, 286, 11666, 4430, 11, 475, 484, 13238, 5566, 287, 511, 10581, 11, 45619, 11, 290, 5479, 13, 3423, 389, 262, 1994, 5400, 25, 198, 198, 21017, 352, 13, 12429, 38816, 14044, 1174, 198, 220, 220, 532, 12429, 48485, 10850, 18252, 1174, 25, 26848, 10107, 3895, 22236, 290, 8705, 13, 20021, 6154, 1690, 761, 284, 5911, 290, 2251, 5981, 3033, 422, 262, 8246, 1366, 284, 2987, 2746, 2854, 13, 198, 220, 220, 532, 12429, 29744, 18252, 1174, 25, 17406, 4142, 22974, 3033, 422, 8246, 1366, 832, 3294, 11685, 286, 17019, 7686, 13, 770, 32311, 262, 761, 329, 10107, 3895, 8705, 11, 2592, 287, 3716, 8861, 588, 2939, 393, 4046, 9465, 13, 198, 198, 21017, 362, 13, 12429, 17633, 29778, 1174, 198, 220, 220, 532, 12429, 48485, 10850, 18252, 1174, 25, 36965, 18599, 16113, 884, 355, 14174, 20683, 11, 2551, 7150, 11, 1104, 15879, 8217, 357, 50, 15996, 828, 290, 479, 12, 710, 12423, 12020, 357, 42, 6144, 737, 2312, 4981, 389, 6032, 19337, 290, 423, 7380, 10007, 13, 198, 220, 220, 532, 12429, 29744, 18252, 1174, 25, 12645, 82, 2769, 17019, 7686, 357, 35, 6144, 82, 8, 351, 3294, 11685, 357, 68, 13, 70, 1539, 3063, 2122, 282, 17019, 7686, 357, 18474, 82, 8, 329, 4263, 11, 42465, 17019, 7686, 357, 49, 6144, 82, 8, 329, 16311, 737, 2312, 4981, 389, 38958, 290, 460, 8006, 28746, 7572, 287, 1366, 13, 198, 198, 21017, 513, 13, 12429, 6601, 24422, 1174, 198, 220, 220, 532, 12429, 48485, 10850, 18252, 1174, 25, 10933, 880, 351, 4833, 40522, 290, 20793, 1366, 13, 632, 460, 4620, 922, 2854, 351, 3614, 1366, 11, 2592, 618, 3033, 389, 880, 12, 23211, 13, 198, 220, 220, 532, 12429, 29744, 18252, 1174, 25, 26848, 1588, 6867, 286, 1366, 284, 4512, 6840, 13, 632, 27336, 82, 351, 555, 7249, 1522, 1366, 357, 68, 13, 70, 1539, 4263, 11, 2420, 11, 6597, 8, 475, 743, 739, 525, 687, 351, 1402, 40522, 2233, 284, 625, 32232, 13, 198, 198, 21017, 604, 13, 12429, 5377, 1996, 864, 13864, 1174, 198, 220, 220, 532, 12429, 48485, 10850, 18252, 1174, 25, 12892, 2653, 15208, 18590, 290, 460, 1690, 1057, 319, 3210, 32340, 13, 13614, 290, 32278, 389, 5443, 290, 2421, 1342, 6890, 13, 198, 220, 220, 532, 12429, 29744, 18252, 1174, 25, 38254, 2653, 15208, 18590, 11, 1690, 10616, 32516, 393, 309, 5105, 82, 329, 3047, 13, 10766, 4981, 460, 1011, 2383, 640, 290, 4133, 284, 4512, 11, 2592, 329, 1588, 40522, 13, 198, 198, 21017, 642, 13, 12429, 9492, 5310, 1799, 1174, 198, 220, 220, 532, 12429, 48485, 10850, 18252, 1174, 25, 32329, 389, 4143, 517, 6179, 540, 13, 1114, 1672, 11, 2551, 7150, 393, 14174, 4981, 2148, 1598, 17218, 656, 703, 16277, 389, 925, 13, 198, 220, 220, 532, 12429, 29744, 18252, 1174, 25, 32329, 389, 1690, 3177, 366, 13424, 10559, 1, 2233, 284, 511, 13357, 13, 28491, 1521, 257, 2769, 4673, 2746, 1838, 257, 2176, 17724]}\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"##### 4. Split the data into train and val:","metadata":{}},{"cell_type":"code","source":"datasets = tokenized_datasets.train_test_split(train_size=0.9, test_size=0.1)\ntrain_dataset = datasets[\"train\"]\neval_dataset = datasets[\"test\"]\nprint(train_dataset)\nprint(eval_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:15:54.622040Z","iopub.execute_input":"2025-04-06T18:15:54.622324Z","iopub.status.idle":"2025-04-06T18:15:54.634522Z","shell.execute_reply.started":"2025-04-06T18:15:54.622294Z","shell.execute_reply":"2025-04-06T18:15:54.633767Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['text', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 27\n})\nDataset({\n    features: ['text', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 3\n})\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"##### 5. Fine tune the model :","metadata":{}},{"cell_type":"code","source":"# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results_gpt2',          # output directory\n    num_train_epochs=10,              # number of training epochs\n    per_device_train_batch_size=4,   # batch size for training\n    per_device_eval_batch_size=8,    # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=10,\n    save_steps=500,\n    eval_strategy=\"steps\",\n    save_total_limit=2,\n)\n\n# Setup Trainer\ntrainer = Trainer(\n    model=model,                         # the model to be trained\n    args=training_args,                  # training arguments\n    train_dataset=train_dataset,         # training dataset\n    eval_dataset=eval_dataset,     # validation dataset\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:16:28.356446Z","iopub.execute_input":"2025-04-06T18:16:28.356799Z","iopub.status.idle":"2025-04-06T18:16:28.401598Z","shell.execute_reply.started":"2025-04-06T18:16:28.356772Z","shell.execute_reply":"2025-04-06T18:16:28.400634Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# Define a custom callback class to log training progress\nclass TrainingLogger(TrainerCallback):\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if logs is not None:\n            # Print the current epoch, global step, and training loss (if available)\n            print(f\"Epoch: {state.epoch:.2f}, Step: {state.global_step}, Loss: {logs.get('train_loss', 'N/A')}\")\n\n\n# cclear any existing callbacks (optional, to avoid duplicates)\ntrainer.callback_handler.callbacks = []\n\n# Add the custom logging callback once\ntrainer.add_callback(TrainingLogger())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:16:30.724533Z","iopub.execute_input":"2025-04-06T18:16:30.724914Z","iopub.status.idle":"2025-04-06T18:16:30.729694Z","shell.execute_reply.started":"2025-04-06T18:16:30.724884Z","shell.execute_reply":"2025-04-06T18:16:30.728694Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"# train the model:\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:16:32.799545Z","iopub.execute_input":"2025-04-06T18:16:32.799912Z","iopub.status.idle":"2025-04-06T18:17:03.237519Z","shell.execute_reply.started":"2025-04-06T18:16:32.799883Z","shell.execute_reply":"2025-04-06T18:17:03.236607Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 10.00, Step: 40, Loss: 54.1775146484375\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=40, training_loss=54.1775146484375, metrics={'train_runtime': 29.8489, 'train_samples_per_second': 9.046, 'train_steps_per_second': 1.34, 'total_flos': 70548848640000.0, 'train_loss': 54.1775146484375, 'epoch': 10.0})"},"metadata":{}}],"execution_count":47},{"cell_type":"markdown","source":"##### 6. store and load the finetuned  model","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"gpt2_finetuned1\")\ntokenizer.save_pretrained(\"gpt2_finetuned1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:17:12.071521Z","iopub.execute_input":"2025-04-06T18:17:12.071886Z","iopub.status.idle":"2025-04-06T18:17:13.158194Z","shell.execute_reply.started":"2025-04-06T18:17:12.071855Z","shell.execute_reply":"2025-04-06T18:17:13.157107Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"('gpt2_finetuned1/tokenizer_config.json',\n 'gpt2_finetuned1/special_tokens_map.json',\n 'gpt2_finetuned1/vocab.json',\n 'gpt2_finetuned1/merges.txt',\n 'gpt2_finetuned1/added_tokens.json',\n 'gpt2_finetuned1/tokenizer.json')"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"model1 = AutoModelForCausalLM.from_pretrained(\"gpt2_finetuned1\")\ntokenizer1 = AutoTokenizer.from_pretrained(\"gpt2_finetuned1\")\ntokenizer1.pad_token = tokenizer1.eos_token\nmodel1.config.pad_token_id = tokenizer1.eos_token_id\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel1.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:24:04.049103Z","iopub.execute_input":"2025-04-06T18:24:04.049397Z","iopub.status.idle":"2025-04-06T18:24:04.427339Z","shell.execute_reply.started":"2025-04-06T18:24:04.049373Z","shell.execute_reply":"2025-04-06T18:24:04.426621Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50258, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2SdpaAttention(\n          (c_attn): Conv1D(nf=2304, nx=768)\n          (c_proj): Conv1D(nf=768, nx=768)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=3072, nx=768)\n          (c_proj): Conv1D(nf=768, nx=3072)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50258, bias=False)\n)"},"metadata":{}}],"execution_count":65},{"cell_type":"markdown","source":"##### 7. Test the model with a sentence","metadata":{}},{"cell_type":"code","source":"input_text = \"how are you\"\ninputs = tokenizer1(input_text, return_tensors=\"pt\").to(model1.device)\noutput = model1.generate(**inputs, max_length=100)\nprint(tokenizer1.decode(output[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:24:27.018026Z","iopub.execute_input":"2025-04-06T18:24:27.018324Z","iopub.status.idle":"2025-04-06T18:24:27.936203Z","shell.execute_reply.started":"2025-04-06T18:24:27.018300Z","shell.execute_reply":"2025-04-06T18:24:27.935358Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"how are you ... ... ... ... ...\n ...\n ...\n ...\n ...\n ...\n ...\n ...\n ...\n ...\n\n","output_type":"stream"}],"execution_count":66},{"cell_type":"markdown","source":"We use a simple dataset to fine-tune the GPT-2 model. \n\nFirstly, GPT-2 is not a highly performant model by today's standards, and to fine-tune it effectively, a large volume of high-quality data is usually required to help it understand complex conversational structures.\n\nSecondly, modern models like **Deepseek** are trained on data with dialogue patterns that differ significantly from those GPT-2 was originally trained on. As a result, our model struggles to understand the structure of the conversations â€” even when increasing the number of training epochs â€” leading to **underfitting**.\n\nTo address this issue, the solution is to work with a more extensive and diverse dataset. That is exactly what we will explore in the second part of this notebook!","metadata":{}},{"cell_type":"markdown","source":"## 4. FINE TUNE USING gooaq DATASET (Part 2) :","metadata":{}},{"cell_type":"markdown","source":"##### 1. Loading the dataset:","metadata":{}},{"cell_type":"markdown","source":"Weâ€™ll use the **gooaq** dataset from Hugging Face's datasets library.","metadata":{}},{"cell_type":"code","source":"# importing the load dataset from datasets :\nfrom datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:49:04.403387Z","iopub.execute_input":"2025-04-07T13:49:04.403838Z","iopub.status.idle":"2025-04-07T13:49:04.409254Z","shell.execute_reply.started":"2025-04-07T13:49:04.403784Z","shell.execute_reply":"2025-04-07T13:49:04.407318Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Load dataset\ndataset = load_dataset(\"gooaq\")\nprint(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:49:06.899431Z","iopub.execute_input":"2025-04-07T13:49:06.899830Z","iopub.status.idle":"2025-04-07T13:53:44.252720Z","shell.execute_reply.started":"2025-04-07T13:49:06.899799Z","shell.execute_reply":"2025-04-07T13:53:44.251908Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/9.45k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"359a979b662248138f4c72bb3cef5be4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"gooaq.py:   0%|          | 0.00/6.00k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edfe3dc4f32e47209ef5b86b3216ca8c"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for gooaq contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/gooaq.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"984e7f006d7a408b9a3ddbca96f28cb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/191M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"010135486df84034b09d1d90f1533456"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3112679 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18f7e12cea52439e8d5691407f3b5118"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b374c253f4349df9c3b7df7c8522859"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e12d9c4b85d4628bf6ad6f4b8213893"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'question', 'short_answer', 'answer', 'answer_type'],\n        num_rows: 3112679\n    })\n    validation: Dataset({\n        features: ['id', 'question', 'short_answer', 'answer', 'answer_type'],\n        num_rows: 2500\n    })\n    test: Dataset({\n        features: ['id', 'question', 'short_answer', 'answer', 'answer_type'],\n        num_rows: 2500\n    })\n})\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# select 30000 rows \ntrain_data = dataset['train'].select(range(30001))\nval_data = dataset['validation'].select(range(1000))\ntest_data = dataset['test'].select(range(1000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:44.253839Z","iopub.execute_input":"2025-04-07T13:53:44.254082Z","iopub.status.idle":"2025-04-07T13:53:44.266946Z","shell.execute_reply.started":"2025-04-07T13:53:44.254047Z","shell.execute_reply":"2025-04-07T13:53:44.266056Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Check the number of rows\nprint(f\"Number of rows in train split: {len(train_data)}\")\nprint(f\"Number of rows in train split: {len(val_data)}\")\nprint(f\"Number of rows in train split: {len(test_data)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:44.268978Z","iopub.execute_input":"2025-04-07T13:53:44.269215Z","iopub.status.idle":"2025-04-07T13:53:44.282041Z","shell.execute_reply.started":"2025-04-07T13:53:44.269195Z","shell.execute_reply":"2025-04-07T13:53:44.281307Z"}},"outputs":[{"name":"stdout","text":"Number of rows in train split: 30001\nNumber of rows in train split: 1000\nNumber of rows in train split: 1000\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Print the first row\nprint(\"First row:\")\nprint(train_data[5625])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:44.283291Z","iopub.execute_input":"2025-04-07T13:53:44.283610Z","iopub.status.idle":"2025-04-07T13:53:44.304738Z","shell.execute_reply.started":"2025-04-07T13:53:44.283579Z","shell.execute_reply":"2025-04-07T13:53:44.304031Z"}},"outputs":[{"name":"stdout","text":"First row:\n{'id': 9388, 'question': '1 decade is equal to how many years?', 'short_answer': '10 Calendar year', 'answer': None, 'answer_type': 3}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Print the second row\nprint(\"Second row:\")\nprint(dataset[\"test\"][1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:44.305472Z","iopub.execute_input":"2025-04-07T13:53:44.305792Z","iopub.status.idle":"2025-04-07T13:53:44.323336Z","shell.execute_reply.started":"2025-04-07T13:53:44.305769Z","shell.execute_reply":"2025-04-07T13:53:44.322481Z"}},"outputs":[{"name":"stdout","text":"Second row:\n{'id': 1322, 'question': '1 acre how many square foot?', 'short_answer': '43560 Square foot', 'answer': None, 'answer_type': 3}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"##### 2. Prepare the data set gooaq:","metadata":{}},{"cell_type":"code","source":"def prepare_data(example):\n    question = example[\"question\"]\n    answer = example[\"short_answer\"]\n    \n    input_text = f\"Question: {question} Answer:\"\n    target_text = answer\n\n    if answer:\n        input_text = f\"Question: {question} Answer:\"\n        target_text = answer\n        \n        return {\n            \"input_text\": input_text,\n            \"target_text\": target_text\n        }\n    return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:44.324207Z","iopub.execute_input":"2025-04-07T13:53:44.324459Z","iopub.status.idle":"2025-04-07T13:53:44.343733Z","shell.execute_reply.started":"2025-04-07T13:53:44.324426Z","shell.execute_reply":"2025-04-07T13:53:44.342468Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# map the function :\nprepared_dataset_train = train_data.map(prepare_data, remove_columns=[\"answer_type\", \"id\", \"short_answer\", 'question', 'answer'])\nprepared_dataset_val = val_data.map(prepare_data, remove_columns=[\"answer_type\", \"id\", \"short_answer\", 'question', 'answer'])\nprepared_dataset_test = test_data.map(prepare_data, remove_columns=[\"answer_type\", \"id\", \"short_answer\", 'question', 'answer'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:44.344772Z","iopub.execute_input":"2025-04-07T13:53:44.345081Z","iopub.status.idle":"2025-04-07T13:53:46.412393Z","shell.execute_reply.started":"2025-04-07T13:53:44.345049Z","shell.execute_reply":"2025-04-07T13:53:46.411383Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/30001 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65f3ed844728466c84ebfc129b5f6545"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7ea2d9db8a341d69ddc2ac4774f7ca2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64494a6e4cd647e28189f3161eacf7c3"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# verify the format :\nprint(prepared_dataset_train)\nprint(prepared_dataset_val)\nprint(prepared_dataset_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:46.415436Z","iopub.execute_input":"2025-04-07T13:53:46.415751Z","iopub.status.idle":"2025-04-07T13:53:46.420405Z","shell.execute_reply.started":"2025-04-07T13:53:46.415715Z","shell.execute_reply":"2025-04-07T13:53:46.419600Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['input_text', 'target_text'],\n    num_rows: 19791\n})\nDataset({\n    features: ['input_text', 'target_text'],\n    num_rows: 775\n})\nDataset({\n    features: ['input_text', 'target_text'],\n    num_rows: 772\n})\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# testing ::\nprint(prepared_dataset_train[10])\nprint(prepared_dataset_val[10])\nprint(prepared_dataset_test[10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:46.421954Z","iopub.execute_input":"2025-04-07T13:53:46.422170Z","iopub.status.idle":"2025-04-07T13:53:46.447185Z","shell.execute_reply.started":"2025-04-07T13:53:46.422150Z","shell.execute_reply":"2025-04-07T13:53:46.446420Z"}},"outputs":[{"name":"stdout","text":"{'input_text': 'Question: 0800 do sac da netflix? Answer:', 'target_text': '1 (866) 579-7172'}\n{'input_text': 'Question: 1 bar is how many pascals? Answer:', 'target_text': '100000 Pascal'}\n{'input_text': 'Question: 1 am pst to est? Answer:', 'target_text': '04:00 Tuesday, Eastern Time (ET)'}\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"##### 3. Saving the data set into txt files:","metadata":{}},{"cell_type":"code","source":"# fucntion to save save the dataset_trained\ndef save_to_file(prepared_dataset, filename):\n    with open(filename, \"w\") as f:\n        for example in prepared_dataset:\n            f.write(f\"{example['input_text']} {example['target_text']}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:46.448123Z","iopub.execute_input":"2025-04-07T13:53:46.448332Z","iopub.status.idle":"2025-04-07T13:53:46.466227Z","shell.execute_reply.started":"2025-04-07T13:53:46.448312Z","shell.execute_reply":"2025-04-07T13:53:46.465533Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# save the train data\nsave_to_file(prepared_dataset_train, \"prepared_gooaq_data_train.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:31:13.829146Z","iopub.execute_input":"2025-04-06T18:31:13.829475Z","iopub.status.idle":"2025-04-06T18:31:14.286435Z","shell.execute_reply.started":"2025-04-06T18:31:13.829450Z","shell.execute_reply":"2025-04-06T18:31:14.285485Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"# save the validation data\nsave_to_file(prepared_dataset_val, \"prepared_gooaq_data_val.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:31:16.526488Z","iopub.execute_input":"2025-04-06T18:31:16.526845Z","iopub.status.idle":"2025-04-06T18:31:16.551302Z","shell.execute_reply.started":"2025-04-06T18:31:16.526818Z","shell.execute_reply":"2025-04-06T18:31:16.550641Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"# save the  test data\nsave_to_file(prepared_dataset_test, \"prepared_gooaq_data_test.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T18:31:18.839828Z","iopub.execute_input":"2025-04-06T18:31:18.840128Z","iopub.status.idle":"2025-04-06T18:31:18.866264Z","shell.execute_reply.started":"2025-04-06T18:31:18.840103Z","shell.execute_reply":"2025-04-06T18:31:18.865535Z"}},"outputs":[],"execution_count":81},{"cell_type":"markdown","source":"##### 3. DATA CLEANING (NAN values) :","metadata":{}},{"cell_type":"code","source":"#cleaning\ndataset_cleaned_train = prepared_dataset_train.filter(lambda example: example['input_text'] is not None and example['target_text'] is not None)\ndataset_cleaned_val = prepared_dataset_val.filter(lambda example: example['input_text'] is not None and example['target_text'] is not None)\ndataset_cleaned_test = prepared_dataset_test.filter(lambda example: example['input_text'] is not None and example['target_text'] is not None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:46.467249Z","iopub.execute_input":"2025-04-07T13:53:46.467574Z","iopub.status.idle":"2025-04-07T13:53:46.628749Z","shell.execute_reply.started":"2025-04-07T13:53:46.467542Z","shell.execute_reply":"2025-04-07T13:53:46.627657Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/19791 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d5c5c4d93c1497abdf0480e7f89bd3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/775 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"212402142dda4253aaaf0cc0fe3b83d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/772 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53f6af738bd64c29adf998f7a76d161f"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# verify the format :\nprint(dataset_cleaned_train)\nprint(dataset_cleaned_val)\nprint(dataset_cleaned_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:46.629606Z","iopub.execute_input":"2025-04-07T13:53:46.629895Z","iopub.status.idle":"2025-04-07T13:53:46.635152Z","shell.execute_reply.started":"2025-04-07T13:53:46.629871Z","shell.execute_reply":"2025-04-07T13:53:46.634351Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['input_text', 'target_text'],\n    num_rows: 19791\n})\nDataset({\n    features: ['input_text', 'target_text'],\n    num_rows: 775\n})\nDataset({\n    features: ['input_text', 'target_text'],\n    num_rows: 772\n})\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"##### 4. Tokenizer the dataset:","metadata":{}},{"cell_type":"code","source":"# Load tokenizer\ntokenizer2 = AutoTokenizer.from_pretrained('gpt2')\ntokenizer2.pad_token = tokenizer2.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:46.636051Z","iopub.execute_input":"2025-04-07T13:53:46.636305Z","iopub.status.idle":"2025-04-07T13:53:48.175039Z","shell.execute_reply.started":"2025-04-07T13:53:46.636281Z","shell.execute_reply":"2025-04-07T13:53:48.174214Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a8b65b2c98f49289d0ddb8be83f2aed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"082b7d0331924cfd9fc74e812ea20bba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb37dd13e39a4036a4385433f00ccabf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"402e556358324f72ac1ae482c116e4d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3d02d70c2284b7a8da2f9967de4d0ea"}},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer2(examples[\"input_text\"], truncation=True, padding=\"max_length\", max_length=512)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:48.175887Z","iopub.execute_input":"2025-04-07T13:53:48.176212Z","iopub.status.idle":"2025-04-07T13:53:48.180248Z","shell.execute_reply.started":"2025-04-07T13:53:48.176180Z","shell.execute_reply":"2025-04-07T13:53:48.179242Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"#train\ntrain_dataset = dataset_cleaned_train.map(tokenize_function, batched=True)\ntrain_dataset = train_dataset.rename_column(\"target_text\", \"labels\")\nprint(train_dataset[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:48.181155Z","iopub.execute_input":"2025-04-07T13:53:48.181440Z","iopub.status.idle":"2025-04-07T13:53:53.215544Z","shell.execute_reply.started":"2025-04-07T13:53:48.181410Z","shell.execute_reply":"2025-04-07T13:53:53.214750Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/19791 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"326af09a404e42a88ef397ab7a0663f9"}},"metadata":{}},{"name":"stdout","text":"{'input_text': 'Question: 0800 da natura do brasil? Answer:', 'labels': '1 (720) 408-2293', 'input_ids': [24361, 25, 657, 7410, 12379, 299, 2541, 64, 466, 48029, 346, 30, 23998, 25, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"#val\nval_dataset = dataset_cleaned_val.map(tokenize_function, batched=True)\nval_dataset = val_dataset.rename_column(\"target_text\", \"labels\")\nprint(val_dataset[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:53.216445Z","iopub.execute_input":"2025-04-07T13:53:53.216743Z","iopub.status.idle":"2025-04-07T13:53:53.465345Z","shell.execute_reply.started":"2025-04-07T13:53:53.216677Z","shell.execute_reply":"2025-04-07T13:53:53.464588Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/775 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94b929101b6e4e8bbed2724d44dbb0cb"}},"metadata":{}},{"name":"stdout","text":"{'input_text': 'Question: 1 acre equal to how many square miles? Answer:', 'labels': '0.0015625 Square mile', 'input_ids': [24361, 25, 352, 31244, 4961, 284, 703, 867, 6616, 4608, 30, 23998, 25, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"#test\ntest_dataset = dataset_cleaned_test.map(tokenize_function, batched=True)\ntest_dataset = test_dataset.rename_column(\"target_text\", \"labels\")\nprint(test_dataset[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:53.466205Z","iopub.execute_input":"2025-04-07T13:53:53.466485Z","iopub.status.idle":"2025-04-07T13:53:53.707727Z","shell.execute_reply.started":"2025-04-07T13:53:53.466455Z","shell.execute_reply":"2025-04-07T13:53:53.706757Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/772 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0babab6b0855418fa965f13109d95594"}},"metadata":{}},{"name":"stdout","text":"{'input_text': 'Question: 1 acer equal to how much square feet? Answer:', 'labels': '43560 Square foot', 'input_ids': [24361, 25, 352, 936, 263, 4961, 284, 703, 881, 6616, 3625, 30, 23998, 25, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# preprocess the data into the GPT-2 input format:\ndef preprocess(example):\n    full_text = example['input_text'] + \" \" + example['labels']\n    \n    encoding = tokenizer2(\n        full_text,\n        truncation=True,\n        padding=\"max_length\",\n        max_length=128  \n    )\n    encoding[\"labels\"] = encoding[\"input_ids\"].copy()\n\n    return encoding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:53.708663Z","iopub.execute_input":"2025-04-07T13:53:53.709029Z","iopub.status.idle":"2025-04-07T13:53:53.713482Z","shell.execute_reply.started":"2025-04-07T13:53:53.709003Z","shell.execute_reply":"2025-04-07T13:53:53.712582Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"tokenized_dataset_inpuutrain = train_dataset.map(preprocess)\ntokenized_dataset_inpuutval = val_dataset.map(preprocess)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:53:53.714429Z","iopub.execute_input":"2025-04-07T13:53:53.714807Z","iopub.status.idle":"2025-04-07T13:54:01.235925Z","shell.execute_reply.started":"2025-04-07T13:53:53.714770Z","shell.execute_reply":"2025-04-07T13:54:01.234668Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/19791 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"991d841575b444488efc7d969ac36ff5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/775 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5622d4d298974c4bb2910ead3cdecfe7"}},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"print(tokenized_dataset_inpuutrain[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:54:01.236912Z","iopub.execute_input":"2025-04-07T13:54:01.237228Z","iopub.status.idle":"2025-04-07T13:54:01.242753Z","shell.execute_reply.started":"2025-04-07T13:54:01.237201Z","shell.execute_reply":"2025-04-07T13:54:01.241890Z"}},"outputs":[{"name":"stdout","text":"{'input_text': 'Question: 0800 da natura do brasil? Answer:', 'labels': [24361, 25, 657, 7410, 12379, 299, 2541, 64, 466, 48029, 346, 30, 23998, 25, 352, 357, 23906, 8, 41247, 12, 1828, 6052, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'input_ids': [24361, 25, 657, 7410, 12379, 299, 2541, 64, 466, 48029, 346, 30, 23998, 25, 352, 357, 23906, 8, 41247, 12, 1828, 6052, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"print(tokenized_dataset_inpuutval[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:54:01.243538Z","iopub.execute_input":"2025-04-07T13:54:01.243811Z","iopub.status.idle":"2025-04-07T13:54:01.325628Z","shell.execute_reply.started":"2025-04-07T13:54:01.243786Z","shell.execute_reply":"2025-04-07T13:54:01.324809Z"}},"outputs":[{"name":"stdout","text":"{'input_text': 'Question: 1 acre equal to how many square miles? Answer:', 'labels': [24361, 25, 352, 31244, 4961, 284, 703, 867, 6616, 4608, 30, 23998, 25, 657, 13, 405, 21599, 1495, 9276, 10591, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'input_ids': [24361, 25, 352, 31244, 4961, 284, 703, 867, 6616, 4608, 30, 23998, 25, 657, 13, 405, 21599, 1495, 9276, 10591, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"##### 5. Load the model and finetune:","metadata":{}},{"cell_type":"code","source":"print(tokenized_dataset_inpuutrain)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:54:01.326791Z","iopub.execute_input":"2025-04-07T13:54:01.327131Z","iopub.status.idle":"2025-04-07T13:54:01.344696Z","shell.execute_reply.started":"2025-04-07T13:54:01.327096Z","shell.execute_reply":"2025-04-07T13:54:01.343929Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['input_text', 'labels', 'input_ids', 'attention_mask'],\n    num_rows: 19791\n})\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Load the pre-trained GPT-2 model\nmodel_fine = AutoModelForCausalLM.from_pretrained(\"gpt2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:54:01.348202Z","iopub.execute_input":"2025-04-07T13:54:01.348428Z","iopub.status.idle":"2025-04-07T13:54:05.058907Z","shell.execute_reply.started":"2025-04-07T13:54:01.348409Z","shell.execute_reply":"2025-04-07T13:54:05.058161Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46a3570897614dbe8eab8c669dc3757e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4a49880618940b7af21b1b8f6641e69"}},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results_gpt2',       # output directory (in kaggle outputs cell !!!)\n    num_train_epochs=10,              # number of training epochs, 10 epochs \n    per_device_train_batch_size=4,   # batch size for training\n    per_device_eval_batch_size=8,    # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=10,\n    save_steps=500,\n    eval_strategy=\"steps\",\n    save_total_limit=2,\n)\n\n# Setup Trainer\ntrainer = Trainer(\n    model=model_fine,                           # the model to be trained (loaded form huggingfacee)\n    args=training_args,                         # training arguments\n    train_dataset=tokenized_dataset_inpuutrain, # training dataset\n    eval_dataset=tokenized_dataset_inpuutval,   # validation dataset\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:54:08.579651Z","iopub.execute_input":"2025-04-07T13:54:08.579951Z","iopub.status.idle":"2025-04-07T13:54:08.626813Z","shell.execute_reply.started":"2025-04-07T13:54:08.579924Z","shell.execute_reply":"2025-04-07T13:54:08.625822Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Define a custom callback class to log training progress\nclass TrainingLogger(TrainerCallback):\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if logs is not None:\n            # Print the current epoch, global step, and training loss (if available)\n            print(f\"Epoch: {state.epoch:.2f}, Step: {state.global_step}, Loss: {logs.get('train_loss', 'N/A')}\")\n\n\n# cclear any existing callbacks (optional, to avoid duplicates)\ntrainer.callback_handler.callbacks = []\n\n# Add the custom logging callback once\ntrainer.add_callback(TrainingLogger())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:54:08.627805Z","iopub.execute_input":"2025-04-07T13:54:08.628144Z","iopub.status.idle":"2025-04-07T13:54:08.633517Z","shell.execute_reply.started":"2025-04-07T13:54:08.628109Z","shell.execute_reply":"2025-04-07T13:54:08.632480Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# train the model:\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T13:54:08.634546Z","iopub.execute_input":"2025-04-07T13:54:08.634843Z","iopub.status.idle":"2025-04-07T15:50:11.162928Z","shell.execute_reply.started":"2025-04-07T13:54:08.634817Z","shell.execute_reply":"2025-04-07T15:50:11.161978Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 10.00, Step: 24740, Loss: 0.1382127051018088\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=24740, training_loss=0.1382127051018088, metrics={'train_runtime': 6962.1118, 'train_samples_per_second': 28.427, 'train_steps_per_second': 3.554, 'total_flos': 1.292807651328e+16, 'train_loss': 0.1382127051018088, 'epoch': 10.0})"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"input_text = \"1m equal what in mm\"\ninputs = tokenizer2(input_text, return_tensors=\"pt\").to(model_fine.device)\noutput = model_fine.generate(**inputs, max_length=100)\nprint(tokenizer2.decode(output[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:53:13.561622Z","iopub.execute_input":"2025-04-07T15:53:13.561973Z","iopub.status.idle":"2025-04-07T15:53:14.259462Z","shell.execute_reply.started":"2025-04-07T15:53:13.561940Z","shell.execute_reply":"2025-04-07T15:53:14.258625Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"1m equal what in mm? Answer: 1000 Millimeter\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"input_text = \"1 acre equal to how many square miles ?\"\ninputs = tokenizer2(input_text, return_tensors=\"pt\").to(model_fine.device)\noutput = model_fine.generate(**inputs, max_length=100)\nprint(tokenizer2.decode(output[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T15:53:19.266455Z","iopub.execute_input":"2025-04-07T15:53:19.266827Z","iopub.status.idle":"2025-04-07T15:53:19.447581Z","shell.execute_reply.started":"2025-04-07T15:53:19.266796Z","shell.execute_reply":"2025-04-07T15:53:19.446766Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"1 acre equal to how many square miles ? Answer: 0.0015625 Square mile\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"input_text = \"c'est quoi cm?\"\ninputs = tokenizer2(input_text, return_tensors=\"pt\").to(model_fine.device)\noutput = model_fine.generate(**inputs, max_length=100)\nprint(tokenizer2.decode(output[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:55:14.887066Z","iopub.execute_input":"2025-04-07T17:55:14.887353Z","iopub.status.idle":"2025-04-07T17:55:14.964790Z","shell.execute_reply.started":"2025-04-07T17:55:14.887330Z","shell.execute_reply":"2025-04-07T17:55:14.963954Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"c'est quoi cm? Answer: 10 Centimeters\n","output_type":"stream"}],"execution_count":112},{"cell_type":"markdown","source":"##### 4. saving the model :\n","metadata":{}},{"cell_type":"code","source":"# saving ...\nmodel_fine.save_pretrained(\"gpt2_finetuned_gooq\")\ntokenizer2.save_pretrained(\"gpt2_finetuned1_gooq\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-08T10:14:44.813Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3. LANGCHIAN PART :\nIn this section, we will integrate **LangChain**, a powerful framework designed to build applications with large language models.\n\nLangChain enables advanced features such as prompt chaining, memory management, retrieval-augmented generation (RAG), and seamless interaction with external tools like vector databases. By using LangChain, we can build more dynamic and context-aware conversational agents.\n\nIn our case, we will use LangChain to connect GPT-2 with **ChromaDB** for retrieving relevant information from stored answers, allowing the model to provide more accurate and enriched responses based on user queries.\n\nThis integration marks a shift from simple text generation to building more intelligent and interactive LLM-powered applications.","metadata":{}},{"cell_type":"code","source":"#!pip install -U langchain-community\n#!pip install chromadb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T10:17:11.455643Z","iopub.execute_input":"2025-04-08T10:17:11.456124Z","iopub.status.idle":"2025-04-08T10:17:11.460696Z","shell.execute_reply.started":"2025-04-08T10:17:11.456083Z","shell.execute_reply":"2025-04-08T10:17:11.459480Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"##### 1. Importing libraries","metadata":{}},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2Tokenizer\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.schema import Document","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:56:11.324492Z","iopub.execute_input":"2025-04-07T17:56:11.324902Z","iopub.status.idle":"2025-04-07T17:56:11.329835Z","shell.execute_reply.started":"2025-04-07T17:56:11.324863Z","shell.execute_reply":"2025-04-07T17:56:11.328954Z"}},"outputs":[],"execution_count":114},{"cell_type":"markdown","source":"##### 2. Loading the fine-tuned model ","metadata":{}},{"cell_type":"code","source":"#load the model:\nmodel = GPT2LMHeadModel.from_pretrained(\"gpt2_finetuned_gooq\")\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2_finetuned1_gooq\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:56:14.186887Z","iopub.execute_input":"2025-04-07T17:56:14.187203Z","iopub.status.idle":"2025-04-07T17:56:14.400611Z","shell.execute_reply.started":"2025-04-07T17:56:14.187176Z","shell.execute_reply":"2025-04-07T17:56:14.399245Z"}},"outputs":[],"execution_count":115},{"cell_type":"markdown","source":"##### 3. Creating some functions :","metadata":{}},{"cell_type":"code","source":"# function to generate the output\ndef generate_response(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\")\n    outputs = model.generate(**inputs, max_length=100)\n    return tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"Answer:\")[1].strip()\n\ndef generate_response1(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\")\n    outputs = model.generate(**inputs, max_length=100)\n    return tokenizer.decode(outputs[0], skip_special_tokens=True).split(prompt)[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:46:44.949665Z","iopub.execute_input":"2025-04-07T18:46:44.950041Z","iopub.status.idle":"2025-04-07T18:46:44.954840Z","shell.execute_reply.started":"2025-04-07T18:46:44.950012Z","shell.execute_reply":"2025-04-07T18:46:44.954109Z"}},"outputs":[],"execution_count":158},{"cell_type":"code","source":"# define a fucntion to store the result\ndef store_output(prompt, response):\n    doc = Document(page_content=response, metadata={\"prompt\": prompt})\n    vectorstore.add_documents([doc])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:08:47.953267Z","iopub.execute_input":"2025-04-07T18:08:47.953588Z","iopub.status.idle":"2025-04-07T18:08:47.957977Z","shell.execute_reply.started":"2025-04-07T18:08:47.953559Z","shell.execute_reply":"2025-04-07T18:08:47.957011Z"}},"outputs":[],"execution_count":130},{"cell_type":"code","source":"# find the retrive similar responses:\ndef retrieve_similar_responses(query, k=2):\n    docs = vectorstore.similarity_search(query, k=k)\n    return [(doc.page_content, doc.metadata) for doc in docs]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T10:22:01.537557Z","iopub.execute_input":"2025-04-08T10:22:01.538002Z","iopub.status.idle":"2025-04-08T10:22:01.543600Z","shell.execute_reply.started":"2025-04-08T10:22:01.537970Z","shell.execute_reply":"2025-04-08T10:22:01.542245Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"##### 4. extract question from test data set :","metadata":{}},{"cell_type":"code","source":"#extract some question (test data set)\ndataset_cleaned_test[100][\"input_text\"].split('Question:')[1].split('Answer:')[0].strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:56:18.870248Z","iopub.execute_input":"2025-04-07T17:56:18.870554Z","iopub.status.idle":"2025-04-07T17:56:18.878382Z","shell.execute_reply.started":"2025-04-07T17:56:18.870529Z","shell.execute_reply":"2025-04-07T17:56:18.877362Z"}},"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"'1 ml is how many cubic feet?'"},"metadata":{}}],"execution_count":117},{"cell_type":"markdown","source":"##### 5. Load the embedding model from huggingFace","metadata":{}},{"cell_type":"code","source":"# Embedding model\nembedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:57:43.865087Z","iopub.execute_input":"2025-04-07T17:57:43.865390Z","iopub.status.idle":"2025-04-07T17:57:44.884653Z","shell.execute_reply.started":"2025-04-07T17:57:43.865367Z","shell.execute_reply":"2025-04-07T17:57:44.883896Z"}},"outputs":[],"execution_count":122},{"cell_type":"markdown","source":"##### 6. Create a chroma base :","metadata":{}},{"cell_type":"code","source":"# Intilize the  Chroma base\npersist_directory='/kaggle/working/results_gpt2'\nvectorstore = Chroma(embedding_function=embedding, persist_directory=persist_directory)\nprint(vectorstore)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:08:42.433436Z","iopub.execute_input":"2025-04-07T18:08:42.433874Z","iopub.status.idle":"2025-04-07T18:08:42.546122Z","shell.execute_reply.started":"2025-04-07T18:08:42.433837Z","shell.execute_reply":"2025-04-07T18:08:42.545277Z"}},"outputs":[{"name":"stdout","text":"<langchain_community.vectorstores.chroma.Chroma object at 0x7b36b70e7610>\n","output_type":"stream"}],"execution_count":129},{"cell_type":"markdown","source":"##### 7. Testing :","metadata":{}},{"cell_type":"code","source":"# test 1 :\nprompt = \"1 centimeter is equal to how many cubic meters\"\n\n# get the response \nresponse = generate_response(prompt)\nprint(\"RÃ©ponse : \", response)\n\n# Storing (chroma db) :\nstore_output(prompt, response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:36:35.020663Z","iopub.execute_input":"2025-04-07T18:36:35.021035Z","iopub.status.idle":"2025-04-07T18:36:35.473082Z","shell.execute_reply.started":"2025-04-07T18:36:35.021004Z","shell.execute_reply":"2025-04-07T18:36:35.472117Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"RÃ©ponse :  1e-6 Cubic meter\n","output_type":"stream"}],"execution_count":152},{"cell_type":"code","source":"# test 2 :\nprompt = \"1 centimeter is equal to how many cubic meters\"\n\n# get the response\nresponse = generate_response(prompt)\nprint(\"RÃ©ponse : \", response)\n\n# storing :\nstore_output(prompt, response)\n\nprint(\"-------------------------\")\n\n# test 3 :\nprompt = \"how many episodes in gentleman jack\"\n\n# get the response\nresponse = generate_response(prompt)\nprint(\"RÃ©ponse : \", response)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:41:29.473129Z","iopub.execute_input":"2025-04-07T18:41:29.473465Z","iopub.status.idle":"2025-04-07T18:41:30.235358Z","shell.execute_reply.started":"2025-04-07T18:41:29.473438Z","shell.execute_reply":"2025-04-07T18:41:30.234509Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"RÃ©ponse :  1e-6 Cubic meter\n-------------------------\nRÃ©ponse :  14 episodes\n","output_type":"stream"}],"execution_count":154},{"cell_type":"code","source":"# MINI chat :\nwhile True:\n        user_message = input(\"Vous : \")\n        if user_message.lower() in [\"exit\", \"stop\"]:\n            print(\"shutdown\")\n            break\n        response = generate_response(user_message)\n        store_output(user_message, response)\n        print(\"GPT :\", response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:49:19.532872Z","iopub.execute_input":"2025-04-07T18:49:19.533170Z","iopub.status.idle":"2025-04-07T18:50:19.014166Z","shell.execute_reply.started":"2025-04-07T18:49:19.533147Z","shell.execute_reply":"2025-04-07T18:50:19.013419Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Vous :  10 am est to tokyo time?\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"GPT : 6:00 PM Thursday, in Tokyo, Japan\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Vous :  10 am mst to cet?\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"GPT : 6:00 PM Thursday, Central European Time (CET)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Vous :  1 oz how much kg?\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"GPT : 0.0283495 Kilogram\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Vous :  exit\n"},{"name":"stdout","text":"shutdown\n","output_type":"stream"}],"execution_count":161},{"cell_type":"markdown","source":"##### 8. Test the similarity fucntion on chroma db:","metadata":{}},{"cell_type":"code","source":"retrieved = retrieve_similar_responses(\"inch\")\nprint(\"similar response : \", retrieved)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:51:19.267355Z","iopub.execute_input":"2025-04-07T18:51:19.267713Z","iopub.status.idle":"2025-04-07T18:51:19.284653Z","shell.execute_reply.started":"2025-04-07T18:51:19.267653Z","shell.execute_reply":"2025-04-07T18:51:19.283980Z"}},"outputs":[{"name":"stdout","text":"similar response :  [(' 7.48052 Inch', {'prompt': ' how many inches in 1 foot ? '}), (' how many inches in 1 foot?  7:33.6 Inch', {'prompt': ' how many inches in 1 foot? '})]\n","output_type":"stream"}],"execution_count":162},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**@MOHAMMED AMHAL**","metadata":{}}]}