{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11315474,"sourceType":"datasetVersion","datasetId":7077791}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LLM Creation with LangChain and PDF Processing:","metadata":{}},{"cell_type":"markdown","source":"**LLM Creation with LangChain and PDF Processing**\n\nIn this notebook, we explore how to build a Retrieval-Augmented Generation (RAG) system using **LangChain**, by leveraging PDFs as a source of knowledge.\n\nThe notebook is structured into three main parts:\n\n**1. PDF Preprocessing and Vectorization**\n\nIn the first part, we preprocess a collection of PDF files by:\n- Cleaning the text and removing unnecessary elements such as images.\n- Splitting the content into manageable chunks.\n- Embedding the chunks using a transformer-based embedding model.\n- Storing the resulting embeddings in a **ChromaDB** vector database for efficient semantic search.\n\n**2. LLM Integration and Simple RAG Function**\n\nIn the second part, we:\n- Import a pre-trained LLM model (e.g., **Mostral**).\n- Store additional PDFs in the ChromaDB using the same embedding process.\n- Build a basic **RAG function**: the function retrieves relevant chunks from ChromaDB based on a user query and combines them with the question to form a context-rich prompt. The LLM then responds based on this augmented context.\n\n**3. End-to-End QA Pipeline with LangChain**\n\nFinally, we use **LangChain's RetrievalQA** pipeline to create a more structured and modular RAG system:","metadata":{}},{"cell_type":"markdown","source":"### 1. Importing libraries :","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nimport torch\nfrom langchain.document_loaders import UnstructuredPDFLoader\nimport os\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.schema import Document\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.chains import RetrievalQA","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T23:00:42.049737Z","iopub.execute_input":"2025-04-07T23:00:42.050116Z","iopub.status.idle":"2025-04-07T23:00:42.219466Z","shell.execute_reply.started":"2025-04-07T23:00:42.050086Z","shell.execute_reply":"2025-04-07T23:00:42.218379Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"#!pip install pdfminer.six\n#!pip install \"unstructured[pdf]\"\n#!pip install chromadb\n#!pip install -U langchain-community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T10:42:07.992127Z","iopub.execute_input":"2025-04-08T10:42:07.992539Z","iopub.status.idle":"2025-04-08T10:42:07.997316Z","shell.execute_reply.started":"2025-04-08T10:42:07.992501Z","shell.execute_reply":"2025-04-08T10:42:07.995910Z"}},"outputs":[{"name":"stdout","text":"The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## 2. Login into huggingface_hub:","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:37:19.953793Z","iopub.execute_input":"2025-04-07T22:37:19.954200Z","iopub.status.idle":"2025-04-07T22:37:20.325173Z","shell.execute_reply.started":"2025-04-07T22:37:19.954167Z","shell.execute_reply":"2025-04-07T22:37:20.324097Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## 3. PDF Preprocessing and Vectorization:","metadata":{}},{"cell_type":"code","source":"# create a variable to store the path:\npdf_folder = \"/kaggle/input/pdfsint/docsPDFS\"  \n# list to store the PDFs con:\ndocs = []\n\n# looping on pdfs ...\nfor filename in os.listdir(pdf_folder):\n    if filename.endswith(\".pdf\"):\n        loader = UnstructuredPDFLoader(os.path.join(pdf_folder, filename))\n        print(loader)\n        docs.extend(loader.load())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:37:22.681514Z","iopub.execute_input":"2025-04-07T22:37:22.682004Z","iopub.status.idle":"2025-04-07T22:42:36.939872Z","shell.execute_reply.started":"2025-04-07T22:37:22.681960Z","shell.execute_reply":"2025-04-07T22:42:36.938714Z"}},"outputs":[{"name":"stdout","text":"<langchain_community.document_loaders.pdf.UnstructuredPDFLoader object at 0x7aabb88267a0>\n<langchain_community.document_loaders.pdf.UnstructuredPDFLoader object at 0x7aab9611fca0>\n<langchain_community.document_loaders.pdf.UnstructuredPDFLoader object at 0x7aab9000d480>\n<langchain_community.document_loaders.pdf.UnstructuredPDFLoader object at 0x7aab904bb340>\n<langchain_community.document_loaders.pdf.UnstructuredPDFLoader object at 0x7aab91bbc9a0>\n<langchain_community.document_loaders.pdf.UnstructuredPDFLoader object at 0x7aab907469e0>\n<langchain_community.document_loaders.pdf.UnstructuredPDFLoader object at 0x7aab90285390>\n<langchain_community.document_loaders.pdf.UnstructuredPDFLoader object at 0x7aab90647490>\n<langchain_community.document_loaders.pdf.UnstructuredPDFLoader object at 0x7aab90502410>\n<langchain_community.document_loaders.pdf.UnstructuredPDFLoader object at 0x7aab915a1ea0>\n<langchain_community.document_loaders.pdf.UnstructuredPDFLoader object at 0x7aab911bb6d0>\n<langchain_community.document_loaders.pdf.UnstructuredPDFLoader object at 0x7aab91d28640>\n<langchain_community.document_loaders.pdf.UnstructuredPDFLoader object at 0x7aab9062a920>\n<langchain_community.document_loaders.pdf.UnstructuredPDFLoader object at 0x7aab919ec400>\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Splitting the content into manageable chunks.\nsplitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\ndocuments = splitter.split_documents(docs)\nprint(len(documents))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:42:36.941311Z","iopub.execute_input":"2025-04-07T22:42:36.942078Z","iopub.status.idle":"2025-04-07T22:42:37.178430Z","shell.execute_reply.started":"2025-04-07T22:42:36.942034Z","shell.execute_reply":"2025-04-07T22:42:37.177281Z"}},"outputs":[{"name":"stdout","text":"5212\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Loading the embedding model from huggingfacee\nembedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n# create a vecto store using chroma db :\nvectorstore = Chroma.from_documents(documents, embedding_model, persist_directory=\"./chroma_db\")\nvectorstore.persist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:42:37.180266Z","iopub.execute_input":"2025-04-07T22:42:37.180654Z","iopub.status.idle":"2025-04-07T22:48:35.807834Z","shell.execute_reply.started":"2025-04-07T22:42:37.180605Z","shell.execute_reply":"2025-04-07T22:48:35.806026Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-7-6c1229e6007c>:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d72a7549741344d3bae6cacdff0f1238"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c815c7f40ab473fa72318bea6ff9bbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04d9df8a53a2468685151779e79f4b8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6e0fa0720f0450180dcc23630ab17b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ead22696dbcf41cbbfa821793698c5ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f970d7aa8eb4e2a869ae3f629e4e99b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"325673d08e3b4286bb0001a731128aaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3864ceb6eb14269bead71a58340ca21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"154612e1ef094a44b89247b556c38a50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"218050427a5b44bf93ce18450cd7413f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f7d798a93834c899de7c02a8732607c"}},"metadata":{}},{"name":"stderr","text":"<ipython-input-7-6c1229e6007c>:3: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n  vectorstore.persist()\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 4. LLM Integration and Simple RAG Function:","metadata":{}},{"cell_type":"code","source":"# fucntion to genrate answers:\ndef generate_answer(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    with torch.no_grad():\n        outputs = model.generate(**inputs, max_new_tokens=200)\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:48:35.809211Z","iopub.execute_input":"2025-04-07T22:48:35.809577Z","iopub.status.idle":"2025-04-07T22:48:35.815688Z","shell.execute_reply.started":"2025-04-07T22:48:35.809545Z","shell.execute_reply":"2025-04-07T22:48:35.814266Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# to search with embedding vectors \":\"\nretriever = vectorstore.as_retriever()\n\n# fucntion use the rap pipeline:\ndef rag_pipeline(query):\n    retrieved_docs = retriever.get_relevant_documents(query)\n    context = \"\\n\".join([doc.page_content for doc in retrieved_docs[:3]])  # top 3\n    prompt = f\"Réponds à la question suivante en te basant sur le contexte donné :\\n\\nContexte:\\n{context}\\n\\nQuestion: {query}\"\n    return generate_answer(prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:48:35.816935Z","iopub.execute_input":"2025-04-07T22:48:35.817295Z","iopub.status.idle":"2025-04-07T22:48:35.836807Z","shell.execute_reply.started":"2025-04-07T22:48:35.817262Z","shell.execute_reply":"2025-04-07T22:48:35.835500Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# laod the tokenizer and mistral model using huggindface:\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\nmodel = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:48:35.837958Z","iopub.execute_input":"2025-04-07T22:48:35.838262Z","iopub.status.idle":"2025-04-07T22:50:54.304064Z","shell.execute_reply.started":"2025-04-07T22:48:35.838235Z","shell.execute_reply":"2025-04-07T22:50:54.302632Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cffeef871714a14b9b7880699217272"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a44af5612c264eb6be8c014d14ac4183"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71a5d27ffb254c59918c7e326420cf5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9cb43da4ab647aabbacf9bb96de6ee6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21bd27eb64c245dfb8a3cbb1c38399e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e61b2fc178449879876dafca1e93e99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"797014a93b99499ba3bb1fb9d57777bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab27c09da86a40e0a81fae5248c1551b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1de43343c4764c46bc6d9c53c020e35d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e6bb469213e475c896c9cc77cbf6f28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7adb7b75e9ac4cffad05dc9a78117924"}},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"### Testing the pipeline :","metadata":{}},{"cell_type":"code","source":"# testing ...\nquestion = \"what's the supervised learning ?\"\nanswer = rag_pipeline(question)\nprint(answer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:51:28.706927Z","iopub.execute_input":"2025-04-07T22:51:28.707346Z","iopub.status.idle":"2025-04-07T22:57:32.743876Z","shell.execute_reply.started":"2025-04-07T22:51:28.707314Z","shell.execute_reply":"2025-04-07T22:57:32.742488Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-9-36c9cf7d3f8f>:4: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n  retrieved_docs = retriever.get_relevant_documents(query)\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Réponds à la question suivante en te basant sur le contexte donné :\n\nContexte:\nSupervised learning: Supervised learning is a process where our machines are designed to learn with the feeding of labelled data. In this process our machine\n\nis being trained by giving it access to a huge amount of data and training the machine to analyze it. For instance, the machine is given a number of images of dogs taken from many different angles with colour variations, breeds and many more diversity. So that, the machine learns to analyze data from these diverse images of dogs and the “insight” of machines keep increasing and soon the machine can predict if it’s a dog from a whole different picture which was not even a part of the labelled data set of dog images the machine was fed earlier.\ninto\n\nSupervised learning includes training a machine learning model on labeled data, which has already been categorized with the correct answers. The machine learning algorithm uses this labeled data to learn how to make predictions or classify new, unlabeled data. In supervised learning, the program is typically written to improve a specific objective function, such as\n\nASEJ ISSN: 2543-9103 ISSN: 2543-411X (online)\n\nminimizing error or maximizing accuracy. (Alpaydin, 2010) Unsupervised learning, involves training a machine learning model on unlabeled data, with the target of discovering underlying patterns or structure within the data. This can be used for tasks such as grouping and dimensionality reduction. (Géron, 2019, 10-23)\ninto\n\nSupervised learning includes training a machine learning model on labeled data, which has already been categorized with the correct answers. The machine learning algorithm uses this labeled data to learn how to make predictions or classify new, unlabeled data. In supervised learning, the program is typically written to improve a specific objective function, such as\n\nASEJ ISSN: 2543-9103 ISSN: 2543-411X (online)\n\nminimizing error or maximizing accuracy. (Alpaydin, 2010) Unsupervised learning, involves training a machine learning model on unlabeled data, with the target of discovering underlying patterns or structure within the data. This can be used for tasks such as grouping and dimensionality reduction. (Géron, 2019, 10-23)\n\nQuestion: what's the supervised learning ?\n\nRéponse:\n\nSupervised learning is a type of machine learning where the machine is trained on a set of labeled data, which means that the data has already been classified or labeled with the correct answers. The machine learning algorithm uses this labeled data to learn how to make predictions or classify new, unlabeled data. In supervised learning, the program is typically written to improve a specific objective function, such as minimizing error or maximizing accuracy. (Alpaydin, 2010)\n\nUnsupervised learning, on the other hand, involves training a machine learning model on unlabeled data, with the target of discovering underlying patterns or structure within the data. This can be used for tasks such as grouping and dimensionality reduction. (Géron, 2019, 10-23)\n\nReferences:\n\nAlpaydin, E. (2010). Introduction\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## 5. End-to-End QA Pipeline with LangChain","metadata":{}},{"cell_type":"markdown","source":"In this block, we build a complete question-answering (QA) pipeline by combining a text generation model (via HuggingFace) with LangChain. First, a `text-generation` pipeline is created using a model and tokenizer, set to generate up to 512 new tokens. This pipeline is then wrapped using `HuggingFacePipeline` to make it compatible with LangChain. Next, we use `RetrievalQA` to connect the language model to a document retriever (`vectorstore`), allowing the model to answer questions based on relevant context. Finally, an interactive `while` loop lets the user input questions, retrieves the most relevant documents, and generates context-aware responses.","metadata":{}},{"cell_type":"code","source":"# create the pipeline :\npipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512)\n# combining the pipe with langchain as a backend :\nllm = HuggingFacePipeline(pipeline=pipe)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:59:42.613164Z","iopub.execute_input":"2025-04-07T22:59:42.613535Z","iopub.status.idle":"2025-04-07T22:59:42.642420Z","shell.execute_reply.started":"2025-04-07T22:59:42.613505Z","shell.execute_reply":"2025-04-07T22:59:42.641156Z"}},"outputs":[{"name":"stderr","text":"Device set to use cpu\n<ipython-input-15-ad107fd1491f>:2: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n  llm = HuggingFacePipeline(pipeline=pipe)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# connect the language model to a document retriever\nqa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T23:00:51.865662Z","iopub.execute_input":"2025-04-07T23:00:51.866034Z","iopub.status.idle":"2025-04-07T23:00:51.871849Z","shell.execute_reply.started":"2025-04-07T23:00:51.866004Z","shell.execute_reply":"2025-04-07T23:00:51.870310Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# simple chat using the language model and documents retriever :\nwhile True:\n        query = input(\"\\question ? : \")\n        if query.lower() in [\"exit\", \"quit\"]:\n            break\n        response = qa_chain.run(query)\n        print(f\"\\nresponse : {response}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T23:03:31.119086Z","iopub.execute_input":"2025-04-07T23:03:31.121089Z","iopub.status.idle":"2025-04-07T23:23:01.730027Z","shell.execute_reply.started":"2025-04-07T23:03:31.120985Z","shell.execute_reply":"2025-04-07T23:23:01.728521Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"\\question ? :  what's deep learning ?\n"},{"name":"stderr","text":"<ipython-input-19-2c79325a2f30>:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n  response = qa_chain.run(query)\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nresponse : Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n\n169 | P a g e\n\nNOVATEUR PUBLICATIONS INTERNATIONAL JOURNAL OF INNOVATIONS IN ENGINEERING RESEARCH AND TECHNOLOGY [IJIERT] ISSN: 2394-3696 VOLUME 7, ISSUE 6, June-2020\n\nDEEP LEARNING Deep learning is a function of Artificial Intelligence that copy's how the human brain works in processing data and pattern creation that are vital in making strategic decisions. Deep learning is also known as a deep neural network since it has systems capable of learning unsupervised data from unstructured data (Hargrave, 2019). Deep knowledge helps to gain massive amounts of unstructured data that makes it strenuous for humans to process and understand (Hargrave, 2019). Deep learning uses a hierarchical level of artificial neural networks that makes the system undergo the process of machine learning (Hargrave, 2019). In general, deep learning artificial intelligence learns from unstructured and unlabeled data. Deep learning AI is vital to an organization since it helps prevent fraud or money laundering.\n\n1.7 The Essence of Deep Learning\n\nThus far, we have talked in broad terms about machine learning. Deep learning is the subset of machine learning concerned with models based on many-layered neural networks. It is deep in precisely the sense that its models learn many layers of transformations. While this might sound narrow, deep learning has given rise to a dizzying array of models, techniques, problem formulations, and applications. Many intuitions have been developed to explain the benefits of depth. Arguably, all machine learning has many layers of computation, the first consisting of feature processing steps. What differentiates deep learning is that the operations learned at each of the many layers of representations are learned jointly from data.\n\n28\n\nIntroduction\n\nSource:http://datasciencecentral.com\n\nDeep Learning, on the other hand is the concept of computers simulating the process a human brain takes to analyze, think and learn. The deep learning process involves something called a neural network as a part of the thinking process for an AI. It takes an enormous amount of data to train deep learning and a considerably powerful computing device for such computation methods.\n\nAI at Work Today\n\nPhoto by Dan Seifert / The Verge\n\nMachine learning is the study of algorithms that can learn from experience. As a machine learning algorithm accumulates more experience, typically in the form of observational data or interactions with an environment, its performance improves. Contrast this with our deterministic e-commerce platform, which follows the same business logic, no matter how much experience accrues, until the developers themselves learn and decide that it is time to update the software. In this book, we will teach you the fundamentals of machine learning, focusing in particular on deep learning, a powerful set of techniques driving in- novations in areas as diverse as computer vision, natural language processing, healthcare, and genomics.\n\n1.1 A Motivating Example\n\nQuestion: what's deep learning ?\nHelpful Answer: Deep learning is a function of Artificial Intelligence that copy's how the human brain works in processing data and pattern creation that are vital in making strategic decisions. Deep learning is also known as a deep neural network since it has systems capable of learning unsupervised data from unstructured data (Hargrave, 2019). Deep learning uses a hierarchical level of artificial neural networks that makes the system undergo the process of machine learning (Hargrave, 2019). In general, deep learning artificial intelligence learns from unstructured and unlabeled data. Deep learning AI is vital to an organization since it helps prevent fraud or money laundering.\n\n1.8 The Essence of Deep Learning\n\nDeep learning is a function of Artificial Intelligence that copy's how the human brain works in processing data and pattern creation that are vital in making strategic decisions. Deep learning is also known as a deep neural network since it has systems capable of learning unsupervised data from unstructured data (Hargrave, 2019). Deep learning uses a hierarchical level of artificial neural networks that makes the system undergo the process of machine learning (Hargrave, 2019). In general, deep learning artificial intelligence learns from unstructured and unlabeled data. Deep learning AI is vital to an organization since it helps prevent fraud or money laundering.\n\n1.7 The Essence of Deep Learning\n\nThus far, we have talked in broad terms about machine learning. Deep learning is the subset of machine learning concerned with models based on many-layered neural networks. It is deep in precisely the sense that its models learn many layers of transformations. While this might sound narrow, deep learning has given rise to a dizzying array of models, techniques, problem formulations, and applications. Many intuitions have been developed to explain the benefits of depth. Arguably, all machine learning has many layers of computation, the first consisting of feature processing steps. What differentiates deep learning is that the operations learned at each of the many layers of representations are learned jointly from data.\n\n1.6 Deep Learning\n\nDeep learning is a function of Artificial Intelligence that copy's how the human brain works in processing data and pattern creation that are vital in making strategic decisions. Deep learning is also known as a deep neural network since it has systems capable of learning unsupervised data from unstructured\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\\question ? :  exit\n"}],"execution_count":19},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**@MOHAMED AMHAL**","metadata":{}}]}